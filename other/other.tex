\chapter{Other design considerations}
\label{chap:Other design considerations}
\begin{secex}
  Chapter about design considerations that does not fit anywhere else
\end{secex}

\section{Disk Support}
\label{sec:Disk Support}
\afigure{img/page-thrashing.png}{This figure show two things. First, when a database system starts spilling pages to disk, the throughput is drastically reduced. Second, databases without buffer managers performs better when data is in memory, but when the OS starts paging, they are much slower than the systems using a buffer manager. Courtesy of \cite{Graefe2014-ds}.}{fig:page-thrashing}{0.7}
In this thesis, we propose a system that will work in-memory. According to research executed by Kemper \ea~\cite{Kemper2011-ap}, this is safe to assume, because ... However, it is important to be aware of the consequences when the database is too large to fit entirely in memory.

The most trivial way to support disk access, is using the operating system virtual memory. This is done by \monetdb~\cite{Boncz2002-yj}, \blink~\cite{Barber2014-ey} and \qlikview~\cite{Qlik2011-ef}. However, the page replacement algorithms for virtual memory has been shown to not work very well on database workloads \todo{find reference of this. Boncz?}. The work of Graefe \ea~\cite{Graefe2014-ds} says that main-memory designed databases suffers a sudden performance drop when virtual memory mechanism starts swapping pages to disk. The VM manager has poor eviction decisions, and are not suited for transactional workloads. Several attempts has been done to mitigate this problem, by exploiting the OS. \qlikview has reported a significant loss in performance once the OS starts paging. This is not the case for \tableau~, which claims their system still performs well even if the data does not fit entirely in memory \cite{Kamkolkar2015-iq}.

There are two ways to mitigate the problems caused by virtual memory. The first one is making your algorithms aware that some pages might be spilled to disk. Larson \ea~explains how \mssql uses a modified hash joining algorithm to avoid the sudden drop in performance once the working set gets too large \cite{Larson2013-mc}. This emphasizes that careful writing to disk is important.

However falling back to virtual memory has been claimed to be unacceptible for performance and correctness reasons \cite{Graefe2014-ds}. To overcome this challenge, major database vendors like \oracle~and \mssql~use buffer managers for all their database operations. However, adding this layer of indirection comes at a significant performance cost. They explain a method where pointers are swizzeled from domain idenfiers to physical identifiers once brought up to memory. This way, they achieve the best of both worlds. \todo{Read the notes from this paper and elaborate} \mssql~has been showed to perform worse than \vertipaq~because the latter does not have a buffer manager \cite{Ferrari2012-hm}


\section{Write-support and mixed workloads}
\label{sec:Write-support and mixed workloads}
\ffigure{img/delta-store-index}{Different index implementation for read optimized store and delta store in \hyrise. Courtesy of \cite{Schwalb2014-hn}.}{fig:delta-store-index}
As explained in Section X, we have focused on read-only workloads. We have seen that this has simplified the design. \tableau, \qlikview, and \vertipaq~has chosen not to support write support, but this is supported in most of the other systems. Some systems are optimized for analycital workloads even though they allow for inserts, updates, and deletes, but some systems suports mixed workloads; that is transactional and analycial workloads equally well. Schwalb \ea~writes that although the traditional OLAP and OLTP separation continues, people have started working on unifying them \cite{Schwalb2014-hn} into OLXP \cite{Plattner2014-fr}. Other vendors, like \oracle and \saph, strive to keep the transparency in the queries, such that applications using the database can be used as it always have been \cite{Lahiri2015-mz, Farber2012-vh}.

Other arguments relates to that real-time analasys is a demand modern businesses \cite{Primsch2011-ij}

We have earlier argued that "one size does not fit all" \cite{Psaroudakis2014-ma}, and there always will be a tradeoff between Data Freshness, Flexibility and Scheduling.

\subsection{Delta Store}
\label{sub:Delta Store}
The most common construct for supporting writes is using a delta store, also known as a insert buffers or write-optimized store \cite{Raman2013-em, Stonebraker2005-qz}. The main reason for this is that an insert operation is not trivial due to several reasons. First, if a column is coded using a dictionary, the key might not exist in the dictionary. If using a sorted dictionary, that means the dictionary will have to be restructured to accomodate for the new key. If the columns are bit packed, the new value might cause an overflow, triggering a column rebuild. Lastly, if the columns themselves are sorted, an insert is likely to trigger a whole column reorganization.

Delta stores is periodically moved into the main storage format, or read-optimized store. Such operation can either be triggered when the delta store exceeds a certain threshold, or through a trickle operation \cite{Lahiri2015-mz, Farber2012-vh}.

\missingfigure{Figure about the delta store in SAP HANA Psaroudakis2014-ma}
A common way to use a delta store is to disallow updates, and use a delete statement followed by an insert statement instead. Deletes are normally implemented as invalidation bit vectors \cite{Raman2013-em, Lamb2012-kg}, and updates are appended to a suitable structure, like an unsorted B+-tree \cite{Psaroudakis2014-ma}, or non-bitpacked columns with unsorted dictionary compression \cite{Farber2012-vh}. This delete-insert way of updating allows for time-travel queries \cite{Scwalb2014-hn, Plattner2014-fr}

In certain conditions, using the delta store can be omited completely on insertion. \mssql~cite allows bulk inserts to create columns directly without going via the delta store \cite{Larson2013-mc}.

\subsection{Transactions}
\label{sub:Transactions}
Transactions can be supported using standard locking and latching used in traditional OLTP databases \cite{Lamb2012-kg}. However, to simplify the design , \hyper~process the transactions serially with a single thread \cite{Psaroudakis2014-ma}. This avoids expensive locking and latching. The analytical queries gets a memory snapshot of the current state of the database by forking the processor, such that hardware facilities for paging can be used.

\subsection{Testing mixed workloads}
\label{sub:Testing mixed workloads}
\ffigure{img/chbench.png}{Schema of the \chbench. Courtesy of \cite{Psaroudakis2014-ma}.}{fig:chbench}
Mixed workloads can be tested using the \chbench, as seen in Figure \ref{fig:chbench}.

\section{Denormalization}
\label{sec:Denormalization}
The technique where you add redundant data and grouping attempting to optimize performance is known as \term{Denormalization} \cite{Wikipedia_contributors2015-az}. It has been studied extensively before \cite{Raman2008-gi}. Among the read-optimized databases, denormalization is not used due to a variety of reasons. First of all, denormalizing offsets the compression \cite{Barber2012-xt}. Second, applying a predicate on a foreign key is easier than applying it on a denormalized fact table \cite{Abadi2008-dd}. \blink was initially denormalizing the data \cite{Johnson2008-cp}, but after checking on customer data, they figured it did not help performance \cite{Barber2012-xt}.

In the case of the reference producs, \qlikview~does not denormalize data internally. However, the data extract script allows users to enter SQL statements such that data can be fetched from other systems, and in this step, denormalization can be applied \cite{Qlik2011-yc}. Both \qlikview~and \tableau~uses star and snowflake schemas, which can be seen as a form of denormalization. Using these schemas boost performance \cite{Kamkolkar2015-iq}.



