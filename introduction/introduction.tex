\chapter{Introduction}
\label{chap:introduction}
\clearpage

\input{introduction/background-and-motivation}
\input{introduction/problem-statement-and-goals}

\subsection{In-Memory}
\label{sub:In-Memory}
We restrict our research to databases that assume the entire dataset can fit in main memory, since preliminary research have shown that this is a commonly used approach to achieve good query performance. Systems capable of using main memory as primary storage include \oracle~\cite{Lahiri2015-mz}, \saph~\cite{Farber2012-vh}, \gorilla~\cite{Pelkonen2015-ko}, \qlikview~\cite{Qlik2011-ef}, \tableau~\cite{Kamkolkar2015-iq}, \monetdb~\cite{Boncz2002-yj}, \blink~\cite{Barber2012-xt}, and \sapnw~\cite{Lemke2010-is}. In-memory database systems can be used where performance and low latency is a key design goal, and on systems that has no need for persistent storage \cite{Zicari2012-is}. It has also been said that in-memory databases are easier optimized using parallelization \cite{Psaroudakis2013-fn}. Lastly, a white paper by \qlikview~suggests that companies looking for \bi~systems should look for in-memory technologies \cite{Bereanu2010-tj}. 

Several of these systems require the database to fit entirely in memory, and does not have a buffer manager. We see in Section \ref{sec:Disk Support} that omiting the buffer manager can increase performance since an extra layer of indirection is removed \cite{Graefe2014-ds}, and it has been shown that databases without buffer managers performs better than those who do \cite{Ferrari2012-hm}. However, databases without buffer managers rely on operating system swapping mechanisms if the database is larger than the provisioned RAM.

According Kemper \ea, it is safe to assume the entire dataset can fit in memory \cite{Kemper2011-ap} if a large scale server is used. Amazon, one of the largest commercial enterprises, has $~1$ billion yearly transactions, and if each transaction is stored using 54 bytes, 54 GB is needed to store all transactions for a year. In addition to this, RAM is getting cheaper \cite{Exasol2014-xh}, and together with 64-bits CPUs \cite{Delaney2014-ip}, in-memory databases are making an increasingly more important role. Much progress has been done in the development of non-volatile RAM, which suggests the era of magnetic disks as the primary database storage hardware might soon be over. \todo{Rephrase paragraph}

It is worth noting that even though we focus on in-memory performance, optimizations performed for disk-based databases will still be applicable. We have just moved one step up through the memery hierarchy \cite{Boncz2002-yj}. That is, optimizations done to better utilize available memory for a disk based database will help an in-memory database utilize available CPU caches. We are aware that certain optimizations are better suited for disk-based databases than for in-memory solutions, however since most research does not specify if they emphasize on disk or in-memory performance, we believe their optimizations contribute to both databaes types. \todo{Make this much clearer}

We continue this research keeping the in-memory assumption true. However, even though DRAM is cheap, it is still rarely over-provisioned and unused \cite{Barber2014-ey}. Therefore, we find techniques that try to keep the memory footprint as low as possible.

\subsection{Read-mostly and Read-only}
\label{sub:Read-mostly and Read-only}
In the first iteration towards the main goal, we assume that the system will be read-only. By not supporting inserts, updates, and deletes, we simplify the database design. In Section \ref{sec:Write-support and mixed workloads}, we explain which techniques might be applied if we need write support.

\ffigure{img/compromise.png}{Conceptual figures of how performance of mixed workloads are affected by (a) data freshness, (b) flexibility, and (c) scheduling. Courtesy of \cite{Psaroudakis2014-ma}.}{fig:compromise}
We choose to focus on read-only because our main design goal is performance. A research paper by Psaurodakis \ea~explains how "one size does not fit all" in a database setting, and in order to get good read performance, data freshness, query flexibility, and query scheduling must be compromised \cite{Psaroudakis2014-ma}. Figure \ref{fig:compromise}~depicts how performance decreases when write support is added. In addition, restricting the research to read-only databases, we limit the scope of the thesis. 

However, we relax the requirement that updates in the underlying data source must be available in our \bd~application once they are performed.

Write support can be separated into two types. The first type is the most involved and first and foremost relates to DBMSes. This type supports inserts, updates, and deletes directly, and in some cases transactions. In these systems, correctness and consistency is the key goal.

The other type which is a more light-weight alternative to the above, is to have the \bd~solution listen to updates performed by another system, say a DBMS. These solutions are not guaranteed to be timely, but timely enough for most cases. \qlikview~and \tableau~supports the latter. If write support is to be considered for \bd~in \genusSoftware, this type is considered first.

To conclude this section, for all practical reasons, we may focus on read-only techniques and can several places assume immutable structures. We do however need some sort of updates, but this can happen in batches or through periodical merge, but we do not need updates in the data to be available to our application immediately. \todo{Adjust entire section to read-mostly.}

\input{introduction/methodology}

\section{Contributions}
\label{sec:Contributions}
\todo{Add from research plan}
The novelty of this thesis is two-fold. Most related work presesnts a single system and explains the techniques use there. Here, we present the litterature by category, not by product. This way, comparisons can be made more easily, and simplifies the process to getting an overview over where the litterature agrees, and where there are contradictions. We have found work X and work Y. These systems present single concepts, but neither of these span as broadly as we do in this thesis.

The second contribution, is a thorough discussion on where the various techniques presented applies. \genusSoftware have several fundamental and practical limitations, and based on these, We present the techniques that are the most fruitful. Optimizations in columnar storage have already been investigated by Abadi \ea~\cite{Abadi2008-dd}, however this work focus on the fundamental differences between row and column stores. We present a more holistic picture, considering more concepts and techniques. In addition to this, this thesis specifically targets \genusSoftware.

\section{Definitions}
\label{sec:Definitions}
This section presents terms, definitions, and important products that are relevant to understading the content of this thesis.

\paragraph{Online Analytical Processing (OLAP)}
\label{par:Online Analytical Processing (OLAP)}
Online Analytical Processing (OLAP) is a term thet we use extensively in this thesis. OLAP is defined as systems capable of analytical queries, typically aggregations over large ranges of rows and groping in one or multiple dimensions. OLAP workloads are typically read-only queries.\todo{Source and improve}

\paragraph{Online Transactional Processing (OLTP)}
\label{par:Online Transactional Processing (OLTP)}
Online Transactional Processing (OLTP) is often considered as the opposite of OLAP. OLTP is defined as systems capable of transactional queries, typically inserts, updates, and deletes. \todo{Source and improve}

\paragraph{Database Management System (DBMS)}
\label{par:Database Management System (DBMS)}
We look into several Database Management Systems (DBMS) in this thesis. These systems are general purpose systems for storage of data. DBMSes can focus on read performance for analytical workloads, write performance for transactional workloads, or both. These systems do not come with user interfaces for \bd, but is designed such that other applications can be built on top of them. The normal interface with the DBMSes is SQL. In this thesis, we look at \oracle, \ibm, \saph, \sapnw, \mssql, \cstore, \vertica, \blink, \exasol, \oracle, \hyper, and \hyrise.

\paragraph{\bd}
\label{par:Business Discovery}
\bd~is a term introduced by \qlikview~\cite{Qlik2014-vd}. \bd~is different from traditional \bi~by focusing more on the end user. By not relying on preaggregated data, the user can follow his own "information scent" and click his way through the data. \bd~platforms delivers panels and dashboards to multiple devices, and allows for easy sharing. They typically build on storage systems that are specifically designed for \bd~workloads, but some of them integrate directly with read-optimized DBMSes. \bd~products include \tableau, \qlikview, \powerpivot, and more. \bd~is explained in greater detail is Section~\ref{sec:Business Discovery}.

\paragraph{Reference products}
\label{par:Reference products}
By reference products we mean product pointed out \genus, products which \bd~in \genusSoftware~will be directly compared to. Studied in this thesis are \qlikview~and \tableau.


\paragraph{\exasol}
\label{par:exasol}
Although not a definition per se, \exasol~is important in this thesis because it is as of November 2015 the highest performing database for the official TPC-H benchmark \cite{noauthor_undated-vr}. This benchmark test datas database performance for analytical workloads on a predefined set of queries on various database sizes ranging from 100 GB to 100,000 GB. \exasol outperforms other systems tested in this benchmark by a factor of 10 in average.

\input{introduction/thesis-structure}


