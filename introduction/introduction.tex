\chapter{Introduction}
\label{chap:introduction}
\clearpage

\input{introduction/background-and-motivation}
\input{introduction/problem-statement-and-goals}

\subsection{In-Memory}
\label{sub:In-Memory}
We restrict our research to databases that assume the entire dataset can fit in main memory since preliminary research have shown that this is a commonly used approach to achieve good query performance. Systems capable of using main memory as primary storage include \oracle~\cite{Lahiri2015-mz}, \saph~\cite{Farber2012-vh}, \gorilla~\cite{Pelkonen2015-ko}, \qlikview~\cite{Qlik2011-ef}, \tableau~\cite{Kamkolkar2015-iq}, \monetdb~\cite{Boncz2002-yj}, \blink~\cite{Barber2012-xt}, and \sapnw~\cite{Lemke2010-is}. In-memory database systems are where performance and low latency is a key design goal, and on systems that have no need for persistent storage \cite{Zicari2012-is}. Psaroudakis \ea~also say that in-memory databases are easier optimized using parallelization \cite{Psaroudakis2013-fn}. Lastly, a white paper by \qlikview~suggests that companies that are looking for \bi~systems should look for in-memory technologies \cite{Bereanu2010-tj}. 

Several of these systems require the database to fit entirely in memory and does not have a buffer manager. We see in Section \ref{sec:Disk Support} that omiting the buffer manager can increase performance since an extra layer of indirection is removed \cite{Graefe2014-ds}, and it has been shown that databases without buffer managers perform better than those who do \cite{Ferrari2012-hm}. However, databases without buffer managers rely on operating system swapping mechanisms if the database is larger than the provisioned RAM.

According to Kemper \ea, it is safe to assume the entire dataset can fit in memory \cite{Kemper2011-ap} if a large scale server is used. Amazon, one of the biggest commercial enterprises of today, has roughly one billion transactions yearly. If each transaction is stored using 54 bytes, 54 GB is needed to store all transactions for a year, an amount that easily can be accommodated on a single commodity server today. Also, RAM is getting cheaper \cite{Exasol2014-xh}, and together with 64-bits CPUs, in-memory databases are getting an increasingly more significant role \cite{Delaney2014-ip}. Much work has been done in the development of non-volatile RAM, which suggests the era of magnetic disks as primary database storage might soon be over.

\afigure{img/memory-hierarchy.png}{Simplified memory hierarchy. Techniques used to utilize the main memory for a hard-disk based database also applies to utilize CPU caches in a main-memory database. Courtesy of \cite{noauthor_undated-bk}.}{fig:memory-hierarchy}{0.5}
Even though we direct our research to in-memory databases, optimization techniques for disk-based databases will normally apply for in-memory databases as well. As seen in Figure \ref{fig:memory-hierarchy}, techniques used to utilize the main memory for a disk-based database can be applied to utilize CPU caches in a main-memory database. We have only moved a step up in the memory hierarchy \cite{Boncz2002-yj}. There are situations where this argument does not hold and one exception is where optimizations are based on the fact that sequential access is cheaper than random access, which does not apply for RAM.

We continue this research keeping the in-memory assumption true. However, even though RAM is cheap, it is still rarely over-provisioned and unused \cite{Barber2014-ey}. Therefore, we will try to find techniques that keep the memory footprint as low as possible.


\subsection{Read-only}
\label{sub:Read-only}
In the first iteration towards the main goal, we assume a read-only system. By not supporting inserts, updates, and deletes, we simplify the database design. In Section \ref{sec:Write Support and Mixed Workloads}, we explain which techniques that might be applied if write support is required.

We choose to focus on read-only because our primary design goal is performance. A research paper by Psaurodakis \ea~explains how "one size does not fit all" in a database setting, and in order to get good read performance \textit{data freshness}, \textit{query flexibility}, and \textit{query scheduling} must be compromised \cite{Psaroudakis2014-ma}. Figure \ref{fig:compromise}~depicts how performance decreases when write support is added. Also, restricting the research to read-only databases, we limit the scope of the thesis. 

\ffigure{img/compromise.png}{Conceptual figures of how performance of mixed workloads are affected by (a) data freshness, (b) flexibility, and (c) scheduling. Courtesy of \cite{Psaroudakis2014-ma}.}{fig:compromise}

Regarding write support, we distinguish between two types. The first, and most involved, relates to database management systems, which we denote as \textit{direct write support}. \textit{Direct write support} implies that the database directly supports inserts, updates, and deletes. Some systems also support transactions. In such databases, correctness and consistency are the main goals, and data written to the database must immediately be accessible for subsequent queries. In such systems, mutable data structures, like invalidation vectors and delta stores are normally used. We elaborate on these structures in Section \ref{sec:Write Support and Mixed Workloads}.


The other type, which we denote as \textit{update based write support}, is a more light-weight alternative to \textit{direct write support}. Here, inserts, updates, and deletes are periodically merged into the database. In other words, an update done to the database might not be available to succeeding queries immediately. \textit{Update based write support} is used by \qlikview~and \tableau, as they can be configured to subscribe to changes in the database they are connected to.

The advantages of \textit{update based write support} is that it does not rely on mutable data structures like invalidation vectors and delta stores. Instead, immutable data structures optimized for read-only workloads can be used. Since updates in such system happen periodically, instances of read-only structures can be replaced with instances of a more recent snapshot.

We conclude it is safe to focus on optimizations for read-only workloads. Even though a \bd~product must be able to handle updates, a \textit{update based write support} type can be used.

\input{introduction/methodology}

\section{Contributions}
\label{sec:Contributions}
\todo{Add from research plan}
The novelty of this thesis is two-fold. Most related work presesnts a single system and explains the techniques use there. Here, we present the litterature by category, not by product. This way, comparisons can be made more easily, and simplifies the process to getting an overview over where the litterature agrees, and where there are contradictions. We have found work X and work Y. These systems present single concepts, but neither of these span as broadly as we do in this thesis.

The second contribution, is a thorough discussion on where the various techniques presented applies. \genusSoftware have several fundamental and practical limitations, and based on these, We present the techniques that are the most fruitful. Optimizations in columnar storage have already been investigated by Abadi \ea~\cite{Abadi2008-dd}, however this work focus on the fundamental differences between row and column stores. We present a more holistic picture, considering more concepts and techniques. In addition to this, this thesis specifically targets \genusSoftware.

\section{Definitions}
\label{sec:Definitions}
This section presents terms, definitions, and important products that are relevant to understading the content of this thesis.

\paragraph{Online Analytical Processing (OLAP)}
\label{par:Online Analytical Processing (OLAP)}
Online Analytical Processing (OLAP) is a term thet we use extensively in this thesis. OLAP is defined as systems capable of analytical queries, typically aggregations over large ranges of rows and groping in one or multiple dimensions. OLAP workloads are typically read-only queries.\todo{Source and improve}

\paragraph{Online Transactional Processing (OLTP)}
\label{par:Online Transactional Processing (OLTP)}
Online Transactional Processing (OLTP) is often considered as the opposite of OLAP. OLTP is defined as systems capable of transactional queries, typically inserts, updates, and deletes. \todo{Source and improve}

\paragraph{Database Management System (DBMS)}
\label{par:Database Management System (DBMS)}
We look into several Database Management Systems (DBMS) in this thesis. These systems are general purpose systems for storage of data. DBMSes can focus on read performance for analytical workloads, write performance for transactional workloads, or both. These systems do not come with user interfaces for \bd, but is designed such that other applications can be built on top of them. The normal interface with the DBMSes is SQL. In this thesis, we look at \oracle, \ibm, \saph, \sapnw, \mssql, \cstore, \vertica, \blink, \exasol, \oracle, \hyper, and \hyrise.

\paragraph{\bd}
\label{par:Business Discovery}
\bd~is a term introduced by \qlikview~\cite{Qlik2014-vd}. \bd~is different from traditional \bi~by focusing more on the end user. By not relying on preaggregated data, the user can follow his own "information scent" and click his way through the data. \bd~platforms delivers panels and dashboards to multiple devices, and allows for easy sharing. They typically build on storage systems that are specifically designed for \bd~workloads, but some of them integrate directly with read-optimized DBMSes. \bd~products include \tableau, \qlikview, \powerpivot, and more. \bd~is explained in greater detail is Section~\ref{sec:Business Discovery}.

\paragraph{Reference products}
\label{par:Reference products}
By reference products we mean product pointed out \genus, products which \bd~in \genusSoftware~will be directly compared to. Studied in this thesis are \qlikview~and \tableau.


\paragraph{\exasol}
\label{par:exasol}
Although not a definition per se, \exasol~is important in this thesis because it is as of November 2015 the highest performing database for the official TPC-H benchmark \cite{noauthor_undated-vr}. This benchmark test datas database performance for analytical workloads on a predefined set of queries on various database sizes ranging from 100 GB to 100,000 GB. \exasol outperforms other systems tested in this benchmark by a factor of 10 in average.

\input{introduction/thesis-structure}


