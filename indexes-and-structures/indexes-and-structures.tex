\chapter{Indexes and Auxiliary Structures}
\label{chap:Indexes and Auxiliary Structures}
Although the of number indexes and materialized views can greatly be reduced by using compressed column storage \cite{Lahiri2015-mz}, \bd~products may still benefit from indexes and other data structures that aid query processing. In this chapter, we look at indexes used for single value lookups, index structures that increase predicate evaluation performance, and join indexes. We also briefly look into caching and preaggregation of results.

Indexes are extensively used in \qlikview. According to a whitepaper on scalability, RAM normally need 2\%-10\% of the application on disk to accomodate overhead such as indexes and data associations.

\newpage

\section{Inverted Indexes}
\label{sec:Inverted Indexes}
\ffigure{img/dictionary.png}{Example of a dictionary compression implementation with inverted indexes. Courtesy of \cite{Psaroudakis2015-lc}.}{fig:dictionary}
\afigure{img/static-inverted-index.png}{A static, dictionary column indexed using an inverted indexes structure. The dictionary (D) is is used to look up positions (P) in the column (AV) using an offset array (O). Courtesy of \cite{Schwalb2014-hn}.}{fig:static-inverted-index}{0.4}

\todo{Explain 5.1, 5.2 better}

Even though most OLAP queries cover a large number of rows, there are situations where a position, or positions, for a single value need to be looked up. This situation benefits from an index structure, and inverted indexes are normally used \cite{Lemke2010-is}. An implementation of inverted indexes for a dictionary encoded column is shown in Figure \ref{fig:dictionary}. 

\hyrise~exploits the fact that the columns are immutable, such that the inverted indexes can be optimized in terms of storage size and cache awareness \cite{Schwalb2014-hn}. Since we operate under the read-only assumption, that is that the columns are immutable, we may also store the inverted indexes in an immutable structure. As seen in Figure \ref{fig:static-inverted-index}, dictionary entries are mapped to an offset vector $O$ over position vector $P$ which contains positions in the column $AV$ containing that value. Since this technique can only be used for single column indexes, separate dictionaries and offset vectors are created for composite indexes. Looking up a composite index requires an extra step, since the original dictionary values must be fetched first.

The inverted index structure explained above is only is suited for situations where the columns are immutable, as adding elements to this will require the entire structure to be rebuilt \cite{Schwalb2014-hn}. Hence, for columns supporting inserts, deletes and updates, tree-based indexes are used instead. \mssql~does not use inverted indexes, only hash and BW-tree indexes \cite{Delaney2014-ip, noauthor_undated-vq}.

However, the cost of keeping inverted indexes must always be weighted against the benefits \cite{Lemke2010-is}, since inverted indexes normally take more space than the documents they are storing \cite{Moffat1992-tz}. If memory footprint must be kept low, inverted indexes should be limited to only a few rows. In certain caseses, inverted indexes might even be skipped entirely

\subsection{Index Lookup vs Table Scan}
\label{sub:Index Lookup vs Table Scan}
Although an index structure exist in the database, there are several situations where a table scan is better than looking up multiple values using an index. Boncz \ea~\cite{Boncz2006-md} shows how easily a table scan should be triggered, and that index based lookups actually can degrade performance. Several researches indicate this \cite{Boncz2002-yj, Abadi2008-dd}. The work of Holloway \ea sees an increased importance of a full table scan \cite{Holloway2008-rr}. \qlikview~has also been reported to calculate much of the results via scans \cite{noauthor_undated-js}. \todo{Back this section up with more theory} 

The most extreme case is found in \blink, a DMBS that has a design goal of constant time query processing \cite{Raman2008-gi}. \blink~systematically avoid structures that benefit particular queries, hence indexes are skipped and tables are accessed using nothing but scans \cite{Barber2012-xt}. This greatly reduces the work of the query optimizer: No need to decide whether to use index lookup or scan, and joins and grouping is always performed in the same order. Even though table scans access more data than index based plans, scans are easier to parallelize and has more consistent runtimes \cite{Raman2008-gi}. The core of \blink~is the generalized scan which performs selection, grouping and aggregation. \todo{Redo this paragraph}

\section{Bitmap Indexes}
\label{sec:Bitmap Indexes}
\ffigure{img/bitmap-query.png}{Executing a query using bitmap indexes. Courtesy of \cite{noauthor_undated-hp}.}{fig:bitmap-query}
A \biti~is a special structure where each distinct value in a column is represented as a bitmap, and all rows containing that value is set to 1. As we have seen in Section \ref{sec:Compression Using Bitmaps}, bitmap indexes can reduce the total storage needed to store a column. However, they can also aid predicate evaluation. A \biti~is most effective on queries that contain multiple \texttt{WHERE} clauses since many candidate rows can be excluded using bitwise \texttt{AND} and \texttt{OR} operations as seen in Figure \ref{fig:bitmap-query} \cite{noauthor_undated-hp}. Since bitmap indexes combine so easily, composite indexes are extraneous. \todo{SEB 30/11: Queries first, then create indexes}

\genusSoftware~reference product \qlikview~reports that it uses binary indexes for each fields \cite{Qlik2011-ef}, which we believe the same as bitmap indexes. Some database management systems also support bitmap indexes, including \oracle~\cite{noauthor_undated-hp} and \ibm~\cite{Raman2013-em}.

In general, low cardinality columns, that is columns with few distinct values, are better suited for bitmap indexes than high cardinality columns \cite{noauthor_undated-hp}. This is because for each unique value in the column, a bitmap must be created and maintained. In addition, since these indexes are hard to maintain, they are not suited for OLTP workloads. When deciding whether to add a \biti~to a column, \oracle~recommends at least 100 rows per distinct value per column, and that the queries put the column in the \texttt{WHERE} clause.

Bitmap indexes may also be used as join indexes, and is much more efficient in storage than storing prejoined materialized views \cite{noauthor_undated-hp}. We study join indexes in Section \ref{sec:Join Indexes}.


\subsection{Compression of Bitmaps}
\label{sub:Compression of Bitmaps}
\ffigure{img/wah.png}{Example WAH compression. Courtesy of \cite{Bjorklund2011-wh}.}{fig:wah}
Since bitmaps in a \biti~are typically sparse, they can be compressed with \rle-like techniques. One popular compression algorithm is the \algmet{WAH} encoding, since it is developed to ensure bitwise operations on the compressed bitmaps are still efficient \cite{Bjorklund2011-wh}. In \algmet{WAH}, if a word size $w$ is used, the bitmap is partitioned into slices with length $w-1$. If the slice contains both 0's and 1's, then the literal bitmap is stored. If it only contains 0's or 1's, run-length encoding is applied by setting the first bit in the word to 1, and the second bit indicating which value that is repeated (0 or 1). The rest of the bits in the word compressed indicate how many sequential words that have the same value. \algmet{WAH} is depicted in Figure \ref{fig:wah}.

Other bitmap compression techniques include parameterizied ways, which is explored by Moffat \ea~\cite{Moffat1992-tz}. In this kind of compression, the total number of 1's is used to generate parameters for efficient bitmap compression. Witten \ea~suggests using a hierarchical compression, since it is very fast to see if a row is present in the bitmap \cite{Witten1999-qq}. \todo{Drop this paragraph or make better}

%Another way of compressing bitmaps is using a parameterized ways, which is explored by \cite{Moffat1992-tz}. Although this article is old, it still indicates that the total number of 1's in a bitmaps should be the main parameter when considering which compression method to use. Hierarchical compression of bitmaps might be used as well \cite{Witten1999-qq}. This method is recommended, since it is very fast to see if a row is present in the bitmap. The key is either way to have fast extraction of single values.

\subsection{Bloom Filter}
\label{sub:Bloom Filter}
Bitmaps can be made smaller at the expense of false matches \cite{Witten1999-qq}. Bloom filters, conceived by Bloom in 1970, is a probabilistic structure with a 100\% recall rate \cite{Bloom1970-nr, Wikipedia_contributors2015-lq}. Words used by Wikipedia Contributers say that a \bloom~returns either "possibly in set" or "definitely not in set" \cite{Wikipedia_contributors2015-lq}. A value can be looked up efficiently in a bloom filter, and will quickly reject values that are not present in the original bitmap. Bloom filters can be used in joins, which we study further in Section \ref{sec:Joining}.

\ffigure{img/bloom-filter.png}{A \bloom~where $x$, $y$, and $z$ is added to the bitmap. $w$ hash to three bits, but since one of bits is set to $0$, $w$ is not in the set. Courtesy of \cite{Wikipedia_contributors2015-lq}.}{fig:bloom-filter}
A bloom filter works by specifying a number of bits used for the filter, and a hash function that hash values to bits in this filter. If a value is added to the set, all 1's are set, but 1's that are 0's in the set is never set back. In order to check if a value is in the set, all 1's for that value is checked. If one of the bits are 0, the value is definitely not in the set, and a false is returned. If all are 1, the value might be in the set, but false positives might also exist since the bits may have been set by a value with the same hash, or the 1s might have been set by multiple different values. The number of elements in the set, as well as the length of the bloom filter determines the false positive rate. See Figure \ref{fig:bloom-filter}.

\subsection{Inverted Indexes vs Bitmap Indexes}
\label{sub:Inverted Indexes vs Bitmap Indexes}
We find several sources that discuss whether to use inverted indexes over bitmap indexes. Witten \ea~claim inverted indexes are almost always superior to bitmap indexes in practical situations \cite{Witten1999-qq}. Bitmap indexes has been used in \term{Information Retrieval} software, but is it now replaced by inverted indexes \cite{Bjorklund2011-wh}. They are faster and generally outperform bitmap indexes. For single value lookups, inverted indexes is normally used instead of bitmap indexes \cite{Moffat1992-tz}.

However, the work of Bjørklund claims that bitmap indexes are widely used in Decision Support Systems \cite{Bjorklund2011-wh}. Stonebraker \ea~has reported that a \biti~is better suited for OLAP workloads \cite{Stonebraker2005-qz}. \oracle~suggest using bitmap indexes in data warehouses, because it improves response time and reduces storage requirements \cite{noauthor_undated-hp}.

We conclude that inverted indexes are better suited for single value lookups on high cardinality columns, and bitmap indexes aids OLAP and data warehouse queries on columns with lower cardinality.

\section{Join Indexes}
\label{sec:Join Indexes}
A \term{Join Index} is a structure that stores precomputed join results to increase join performance. Although a \term{Join Index} can have various implementations, a bitmap is the most common representation \cite{Bjorklund2011-wh}. Join indexes are explicitly used by \monetdb~\cite{Boncz2002-yj}, \monetx~\cite{Boncz2005-wj}, and \oracle~\cite{noauthor_undated-hp}. In addition, since \exasol~reports an ability to cache joins \cite{Exasol2014-xh}, we believe similar techniques are used here.

\begin{figure}
    \centering
    \begin{tabular}{l | c | c}
     & customer\_gender='M' & customer\_gender='F'  \\
     \hline
     Sales Record 1 & 1 & 0 \\
     Sales Record 2 & 0 & 1 \\
     Sales Record 3 & 1 & 0 \\
     Sales Record 4 & 1 & 0 \\
     Sales Record 5 & 1 & 0 \\
     Sales Record 6 & 1 & 0 \\
     Sales Record 7 & 1 & 0 \\
    \end{tabular}
    \caption{A join index the customer's gender for the sales record. With this index, sales by each gender can easily be found. Courtesy of \cite{noauthor_undated-xi}.}
    \label{fig:oracle-join-index}
\end{figure}

In \oracle, join indexes are bitmap indexes on foreign key columns, and is a space efficient way of reducing the join data volume by applying restrictions to the tables before entering the join \cite{noauthor_undated-xi}. As seen in Figure \ref{fig:oracle-join-index}, a \term{Join Index} stores a bitmap for every distinct value in a foreign column. Using join indexes, \oracle~may improve performance by one order of magnitude \cite{noauthor_undated-hp}.

\afigure{img/join-index.png}{Example join index structure in \cstore. Courtesy of \cite{Stonebraker2005-qz}.}{fig:join-index}{0.4}
\cstore~uses join indexes to reconstruct tuples from the original table \cite{Lamb2012-kg}, as seen in Figure \ref{fig:join-index}. \monetdb~and \monetx~work similarly \cite{Boncz2002-yj, Boncz2005-wj}. However, in the commercialization of \cstore, \vertica, this construct was dropped entirely since the benefits was outweighted by the costs. The join indexes was hard to maintain, and they consumed significant disk space for large tables. \todo{SEB 30/11: How do they cope without it? Explain figure better.}


\section{Database Statistics}
\label{sec:Database Statistics}
\term{Database Statistics} is commonly used by a query optimizer to make better decisions about creating efficient execution plans. These statistics may include number of records, selectivity, column cardinality, value distribution, and more. In our case, \term{Database Statistics} can be used to prune horizontal partions based on the column minimum and maximum value. This exploits clustering in the columns, especially when the columns are sorted, or partially sorted, like timestamps. The storing of block metadata for quick data pruning is used by \oracle~\cite{Lahiri2015-mz}, \ibm~\cite{Raman2013-em}, \vertica~\cite{Lamb2012-kg}, \monetx~\cite{Boncz2005-wj}, \mssql~\cite{Larson2013-mc}, and \exasol~\cite{Exasol2014-xh}.

Most database systems keep the statistics stored together with the table, however other schemes exist. \ibm~uses a synopsis table to keep track over all column partitions (pages), including mininmum and maximum values. This way, irrelevant pages can easily be skipped \cite{Raman2013-em}.

We have previously discussed how a partition dictionary can be checked for a key's existence before scanning an entire block, that is, if a key is not present in the dictionary, the partition can be skipped. We consider this technique as a part of utilizing \term{Database Statistics} to improve performance.

It can sometimes be useful to know a column's value distribution. A column's value distribution is used when determining the frequency partitioning used in \blink~and \ibm~\cite{Raman2008-gi, Raman2013-em}. The query optimizer in \mssql~also uses the value distributions when creating execution plans \cite{Larson2013-mc}. Value distributions are normally determined by creating histograms, and to make these, random sampling can be used. Two techniques apply: The first one is truly random, where values are picked across the whole column. The second one is a grouped version, where a random sample range is picked.

\section{Data Duplication and Pre-Aggregation}
\label{sec:Data Duplication and Pre-Aggregation}
Performance can be boosted by data duplication. \cstore~and \vertica~allows for storing the columns in multiple sort orders at the same time \cite{Stonebraker2005-qz, Lamb2012-kg} to increase query performance for certain queries. The sort orders are defined by a database administrator. In these systems, the extra storage needed to store columns in multiple sort orders are justified by the compression enabled by column storage.

\blink~allows for storing columns in multiple banks, such that predicates can be evaluated in the same bank \cite{Johnson2008-cp}. This does not use more storage, as only columns that fit within the free space in a word will be added. In Figure \ref{fig:banked-layout}, this means the A column can be placed in both bank $\beta 1$ and $\beta 2$, since A fits within $\beta 2$ as well.

Data can also be duplicated across nodes in a distributed environment. \exasol~replicates tables across nodes in the system if they are small enough, such that queries can be processed more efficiently. This is typically used in a \bi~scenario where the dimension tables are replicated across different nodes. This results in turning a costly global operation into a cheap local one \cite{Exasol2014-xh}.

Historically, data was preaggregated to achieve good performance, but this has been considered as inflexible and one of the main challenges with old ROLAP and MOLAP systems \cite{Boncz2002-yj}. Therefore, most modern systems do not preaggregate results, like \sapnw~\cite{Lemke2010-is} and \qlikview~\cite{Qlik2014-vd}, and calculate all results as needed. However, \qlikview~ allows data to be preaggregated when loaded into memory \cite{Qlik2011-yc}.

%Another way to boost performance, is through data duplication. \label{sub:Column projections}  C-store allows to have several projections per column, with different sort order. They claim the redundant storage is justified by the additional compression. Configuring these projections requires a DBA. \pn{Vertica}, a commercialized version of \pn{C-Store} supports several narrow projections in addition to one super projection.


\section{Caching and Dynamic Index Generation}
\label{sec:Caching and Dynamic Index Generation}
To improve performance and keep the system scalable, caching can be used \cite{Plattner2014-fr}. \exasol~stores the results of previous queries along with metadata that allows the system to decide if records are still valid \cite{Exasol2014-xh}. 

In \bd~products, which are mostly read-only, caching can be used more aggressively. In \qlikview~and \tableau, the server has a central cache function such that calculations only need to be done once \cite{Kamkolkar2015-iq, Qlik2011-ef}. This gives better user experience and lower the CPU footprint. When deciding which results to cache, the system takes into consideration how long it takes to generate the results \cite{noauthor_undated-js}. In addition, cache is shared among users \cite{Qlik2011-yc}. In \tableau, data and calculations are cached and shared among the users \cite{Kamkolkar2015-iq}. \vertipaq~also cache data, and this improves performance compared to \mssql~\cite{Ferrari2012-hm}.

Caches are normally shared among different users on the same server. This is done in \qlikview~and \tableau~\cite{Kamkolkar2015-iq, Qlik2011-yc}. We see in Section \ref{sec:Scaling} that server cache is an argument for scale-up.

Not only query results, but also intermediate structures used in the query can be cached. Join Indexes are used extensively by \exasol, and they are produced, maintained, and deleted as needed \cite{Exasol2014-xh}. This gives faster filter operations. \monetxq~creates temporary indexes on non-equie theta-joins \cite{Boncz2006-md}.

\todo{Safety issues}

%Hence, if adding "one user at a time", the cache builds up, and the system can gradually serve more and more users. 
%In dedicated database systems, like the \exasol, joins, queries, and aggregates are cached to keep the system scalable \cite{Exasol2014-xh, Plattner2014-fr}. 

%The cache can be put in the delta store, mentioned in Section \ref{sub:Delta Store}.



\section{Chapter Conclusion}
\label{sec:Chapter Conclusion}
We conclude this chapter by acknowledging that indexes and other structures are required for a \bd~product.

We point at \biti~as the most promising index structure. It is well suited for OLAP workloads, handles \texttt{WHERE} clauses well, and can be used as a join index at the same time. We also suggest looking into bitmap compression schemes, like \algmet{WAH} compression, since this allows for bitwise operations on the compressed bitmap.

We find \term{Table Statistics} to be important for query performance. By checking minimum and maximum values for column partitions, data can easily be pruned by exploiting local clustering. We also suggest looking up the dictionary and check if the value is present.

We find all of the studied \bd~products, \qlikview, \powerpivot, \tableau, to cache data and calculation results. The same is the case for \exasol, which also creates, maintains, and deletes indexes as needed. We therefore reccommend caching data in our implementation of \bd~capabilities. Data candidate for caching are not limited to query results, intermediate structures used in the query processing may be cached, especially join indexes. We look closer into which structures that can be cached in Chapter \ref{chap:Query Processing}.

We are reluctant to recommend inverted indexes~in a \bd~product, as they consume much memory and we are unsure of how important single value lookups will be in such application.

%\section{Partition Indexing}
%\label{sec:Partition Indexing}
%If columns are horizontally partitioned, as discussed in Section \ref{sec:Horizontal Partitioning}, an index structure might be required to look up the partitions. \ibm~uses a B+ tree for this purpose \cite{Raman2013-em}.

