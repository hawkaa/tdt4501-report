\chapter{Indexes and Auxiliary Structures}
\label{chap:Indexes and Auxiliary Structures}

Although the of number indexes and materialized views can significantly be reduced by using compressed column storage \cite{Lahiri2015-mz}, and perhaps the main idea behind column store is that indexes can be dropped, \bd~products may still benefit from indexes and other data structures that aid query processing. In this chapter, we look at inverted indexes for single value lookups, bitmap indexes for increased performance on analytical workloads, and join indexes that increase join performance. We also briefly study caching and pre-aggregation of results.

One of the reasons why we have devoted more than half a chapter to indexes is because indexes are extensively used in \qlikview. According to a whitepaper on scalability, RAM normally need 2\%-10\% of the application on disk to accommodate overhead such as indexes and data associations.

\newpage

\section{Inverted Indexes}
\label{sec:Inverted Indexes}

\ffigure{img/dictionary.png}{Example of a dictionary compression implementation with inverted indexes. The Index Vector (IV) is the actual column, with keys referring to the dictionary. IX is the inverted index structure, which consists of two parts; an offset vector (prefix sum) and a position vector. The offset vector has the same length as the dictionary and is used to look up values in the IX position vector. Courtesy of \cite{Psaroudakis2015-lc}.}{fig:dictionary}

\afigure{img/static-inverted-index.png}{A static, dictionary encoded column with an inverted index structure, and how the structures relate to each other. The dictionary (D) is used to look up positions (P) in the column (AV) using an offset array (O). Courtesy of \cite{Schwalb2014-hn}.}{fig:static-inverted-index}{0.4}

Even though most queries for OLAP databases cover a large number of rows, there are situations where a position, or several positions, for single values need to be looked up. This situation benefits from an index structure, and commonly used for this are inverted indexes \cite{Lemke2010-is}. 

An inverted index is a data structure that stores mappings from values to positions, such that positions of a given value are easily looked up \cite{Wikipedia_contributors2015-gt}. Inverted indexes are commonly used in document retrieval systems, like search engines, but as we see in this section, it can also be used for OLAP databases.

\hyrise~exploits the fact that the columns are immutable, such that the inverted indexes can be optimized regarding storage size and cache awareness \cite{Schwalb2014-hn}. Said in other words, the inverted index can be immutable itself. Figure \ref{fig:dictionary} shows how an immutable inverted index for a dictionary encoded column can be implemented using an offset vector (prefix sum) and a position vector. Figure \ref{fig:static-inverted-index} shows the structures at a greater level of abstraction and how they relate to each other. Since this technique can only be used for single-column indexes, separate dictionaries and offset vectors are created for composite indexes. Looking up a composite index requires an extra step since the original dictionary values must be fetched first.

The inverted index structure explained in the above paragraph is only is suited for situations where the columns are immutable, as adding elements will require the entire structure to be rebuilt \cite{Schwalb2014-hn}. Hence, for columns supporting inserts, deletes, and updates, tree-based indexes are used instead. For instance, \mssql~does not use inverted indexes, only hash and BW-tree indexes \cite{noauthor_undated-vq, Delaney2014-ip}.

The cost of keeping inverted indexes must always be weighed against the benefits \cite{Lemke2010-is} since inverted indexes normally take more space than the values they are indexing \cite{Moffat1992-tz}. If low memory footprint is important, inverted indexes should be limited to only a few columns, or skipped entirely.

\subsection{Index Lookup vs Table Scan}
\label{sub:Index Lookup vs Table Scan}
Although an index structure exists for a column, there are several situations where a table scan will perform better than looking up one value at a time from an index. Index lookups can turn sequential memory access into random memory access, which can hurt cache performance \cite{Boncz2002-yj}. Even though table scans access more data than index based plans, scans are easier to parallelize and have more consistent runtimes \cite{Raman2008-gi}. \qlikview~has been reported to calculate much of its results via scans \cite{noauthor_undated-js}.

The most extreme case is found in \blink, a DMBS that has a design goal of constant time query processing \cite{Raman2008-gi}. \blink~systematically avoid structures that benefit particular queries; hence, indexes are not supported, and tables are accessed using scans only \cite{Barber2012-xt}. The lack of indexes greatly reduces the work of the query optimizer; no need to decide whether to use index lookup or scan. The idea core of \blink~is a generalized scan that performs selection, grouping, and aggregation. 

\section{Bitmap Indexes}
\label{sec:Bitmap Indexes}

\ffigure{img/bitmap-query.png}{Executing a query using bitmap indexes. Queries are efficiently processed using bitwise operations like \texttt{AND} and \texttt{OR}. Courtesy of \cite{noauthor_undated-hp}.}{fig:bitmap-query}

A \biti~is a particular structure where a bitmap represents each distinct value in a column, and all rows containing that value is set to 1. As we have seen in Section \ref{sec:Compression Using Bitmaps}, bitmap indexes can reduce the storage requirements for a column. However, the bitmaps can also aid predicate evaluation as the form of a \biti. A \biti~is most efficient on queries that contain multiple \texttt{WHERE} clauses since many candidate rows can be excluded using bitwise \texttt{AND} and \texttt{OR} operations, as seen in Figure \ref{fig:bitmap-query} \cite{noauthor_undated-hp}. Since bitmap indexes combine so easily, composite indexes are extraneous. 

One of our reference products, \qlikview, reports that it uses binary indexes for each field \cite{Qlik2011-ef}, which we believe are the same as bitmap indexes. Some database management systems also support bitmap indexes, including \oracle~\cite{noauthor_undated-hp} and \ibm~\cite{Raman2013-em}.

In general, low-cardinality columns, which is columns with few distinct values, are better suited for bitmap indexes than high-cardinality columns \cite{noauthor_undated-hp}. The reason for this is because a bitmap must be created and maintained for each unique value in the column. Besides, since these indexes are hard to maintain, they are not suited for inserts, updates, and deletes. When deciding whether to add a \biti~to a column, \oracle~recommends at least 100 rows per distinct value. 

Bitmap indexes may also be used as join indexes, and is much more efficient in storage than storing pre-joined materialized views \cite{noauthor_undated-hp}. We study join indexes in Section \ref{sec:Join Indexes}.


\subsection{Compression of Bitmaps}
\label{sub:Compression of Bitmaps}

\ffigure{img/wah.png}{Example WAH compression. For a compression with word size $w$, the original bitmap is partitioned into slices with a length of $w-1$. If a partition contains both 0s and 1s, the literal bitmap for that partition is stored. If a series of partitions contain only 0s or only 1s, the partitions are stored in a run-length encoded fashion. Courtesy of \cite{Bjorklund2011-wh}.}{fig:wah}

Since bitmaps in a \biti~are typically sparse, they can be compressed with \rle-like techniques. One popular compression algorithm is the \algmet{WAH} encoding since it is developed to ensure bitwise operations on the compressed bitmaps are still efficient \cite{Bjorklund2011-wh}. In \algmet{WAH}, if a word size $w$ is used, the bitmap is partitioned into slices with length $w-1$. If the slice contains both 0s and 1s, then the actual bitmap is stored. If it only contains 0s or 1s, run-length encoding is applied by setting the first bit in the word to 1, and the second bit indicating which value that is repeated (0 or 1). The rest of the bits in the compressed word indicate how many subsequent words that have the same value. \algmet{WAH} is depicted in Figure \ref{fig:wah}.

Other bitmap compression techniques include parameterized ways, which is explored by Moffat \ea~\cite{Moffat1992-tz}. In parameterized compression, the total number of 1s in a bitmap is used to generate parameters for efficient bitmap compression. Another method is hierarchical compression, which is suggested by Witten \ea~\cite{Witten1999-qq}. With hierarchical compression, it is very effective to look up whether a row is present in the bitmap.


\subsection{Bloom Filters}
\label{sub:Bloom Filter}
Bitmaps can be made smaller at the expense of false matches \cite{Witten1999-qq}. Bloom filters, conceived by Bloom in 1970, is a probabilistic structure with a 100\% recall rate \cite{Bloom1970-nr, Wikipedia_contributors2015-lq}. According to Wikipedia contributors, a \bloom~returns either "possibly in the set" or "definitely not in the set" \cite{Wikipedia_contributors2015-lq}. A \bloom~efficiently looks up values, and will quickly reject values that are not present in the original bitmap. Bloom filters can be used in joins, which we study further in Section \ref{sec:Joining}.

\ffigure{img/bloom-filter.png}{A \bloom~where each $x$, $y$, and $z$ sets three partially overlapping bits on the filter. $w$ also hashes to three bits, but since one of bits are $0$, $w$ is not in the set. Courtesy of \cite{Wikipedia_contributors2015-lq}.}{fig:bloom-filter}

A \bloom~is specified by a number of bits, which is the length of the filter, and a hash function that map values to bits in the filter. When a value is added to the set, the value is hashed, and the bits resulting from the hash function are set in the filter. Figure \ref{fig:bloom-filter} shows an example where value $x$ map to bit 2, 6, and 14, $y$ map to bit 5, 12, 17, and $z$ to bit 4, 6, and 12. In this example, the bits are overlapping, which is one of the reasons why a bloom filter takes less space than a literal bitmap.

To check if a value is present in the set, the value is hashed and the bits in that hash are compared with the \bloom. If one or more of the bits are 0, the value is surely not in the set. If all bits are 1, the value might be in the set. However, there is a chance of false positives for two reasons: (i) There might another value that has the same hash, and (ii) the 1s might have been set by multiple values. The number of elements in the set, as well as the length of the \bloom~determines the false positive rate.


\subsection{Inverted Indexes vs Bitmap Indexes}
\label{sub:Inverted Indexes vs Bitmap Indexes}
We find several sources that discuss whether to use inverted indexes over bitmap indexes. Witten \ea~claim inverted indexes are almost always superior to bitmap indexes in practical situations \cite{Witten1999-qq}. Bitmap indexes have been used in \term{Information Retrieval} software, but is it now replaced by inverted indexes \cite{Bjorklund2011-wh}. They are faster and generally outperform bitmap indexes, especially for single value lookups \cite{Moffat1992-tz}.

However, the work of Truls A. Bj√∏rklund claims that bitmap indexes are widely used in Decision Support Systems \cite{Bjorklund2011-wh}. Also, Stonebraker \ea~has reported that a \biti~is suited for OLAP workloads \cite{Stonebraker2005-qz}. \oracle~suggest using bitmap indexes in data warehouses, because it improves response time and reduces storage requirements \cite{noauthor_undated-hp}.

We conclude that inverted indexes are better suited for single value lookups on high cardinality columns, and bitmap indexes are better for analytical workloads and data warehouse queries on columns with lower cardinality.


\section{Join Indexes}
\label{sec:Join Indexes}
A \term{Join Index} is a structure that stores precomputed join results to increase join performance. Although a \term{Join Index} can have various implementations, a bitmap is the most common representation \cite{Bjorklund2011-wh}. Join indexes are explicitly used by \monetdb~\cite{Boncz2002-yj}, \monetx~\cite{Boncz2005-wj}, and \oracle~\cite{noauthor_undated-hp}. Also, since \exasol~reports an ability to cache joins \cite{Exasol2014-xh}, we believe this system uses similar techniques.

\begin{figure}
    \centering
    \begin{tabular}{l | c | c}
     & customer\_gender='M' & customer\_gender='F'  \\
     \hline
     Sales Record 1 & 1 & 0 \\
     Sales Record 2 & 0 & 1 \\
     Sales Record 3 & 1 & 0 \\
     Sales Record 4 & 1 & 0 \\
     Sales Record 5 & 1 & 0 \\
     Sales Record 6 & 1 & 0 \\
     Sales Record 7 & 1 & 0 \\
    \end{tabular}
    \caption{A join index for the customer's gender for a sales table. The sales table does not contain a gender column, only a foreign key to the customer table (which has gender). Using this index, sales by each gender can easily be found. Courtesy of \cite{noauthor_undated-xi}.}
    \label{fig:oracle-join-index}
\end{figure}

In \oracle, join indexes are bitmap indexes on foreign columns and is a space efficient way of reducing the join data volume by applying restrictions to the tables before entering the join \cite{noauthor_undated-xi}. As seen in Figure \ref{fig:oracle-join-index}, a \term{Join Index} stores a bitmap for every distinct value in a foreign column. Using join indexes, \oracle~may improve performance by one order of magnitude \cite{noauthor_undated-hp}.

\afigure{img/join-index.png}{Example join index structure in \cstore. The join index is used to stitch together rows from the original table when a query span multiple projections. Courtesy of \cite{Stonebraker2005-qz}.}{fig:join-index}{0.5}

A join index in \cstore~is implemented differently and has another use case than in \oracle~\cite{Lamb2012-kg}. A join index in \cstore is used to stitch together tuples from the original table when a query spans multiple projections. In Figure \ref{fig:join-index}, we see two projections, each containing different columns, and how a join index is used to stitch the columns back together. However, in the commercialization of \cstore, \vertica, join indexes were dropped entirely since the benefits were outweighed by the costs. The join indexes were hard to maintain, and they consumed significant disk space for large tables. Instead, \vertica~requires at least one \textit{super projection} that contains all columns in the original table.

\section{Database Statistics}
\label{sec:Database Statistics}
\term{Database Statistics} are commonly used by a query optimizer to make better decisions about creating efficient execution plans. These statistics may include number of records, selectivity, column cardinality, value distribution, and more. In our case, \term{Database Statistics} can be used to prune horizontal partions based on the column minimum and maximum values. This technique exploits clustering in the columns, especially when the columns are sorted, or partially sorted, like timestamps. \oracle~\cite{Lahiri2015-mz}, \ibm~\cite{Raman2013-em}, \vertica~\cite{Lamb2012-kg}, \monetx~\cite{Boncz2005-wj}, \mssql~\cite{Larson2013-mc}, and \exasol~\cite{Exasol2014-xh} stores partition metadata for quick data pruning.

Most database systems keep the statistics stored together with the table. However, other schemes exist. \ibm~uses a synopsis table to keep track of all column pages (partitions), including minimum and maximum values. This way, irrelevant pages can easily be skipped \cite{Raman2013-em}.

We have previously discussed how a partition dictionary can be checked for a key's existence before scanning an entire block. If a key is not present in the dictionary, the partition can be skipped. We consider this technique as a part of utilizing \term{Database Statistics} to improve performance.

It can sometimes be useful to know a column's value distribution. For instance, the frequency partitioning in \blink~and \ibm~uses the columns' value distributions when determining how to partition the data \cite{Raman2008-gi, Raman2013-em}. The query optimizer in \mssql~also uses the value distributions when creating execution plans \cite{Larson2013-mc}. Value distributions are usually determined by creating histograms, and to make these histograms, random sampling can be used. In \mssql, two techniques are used: One is truly random, where values are picked across the whole column, and one is a grouped version, where a random sample range is picked.

\section{Data Duplication and Pre-Aggregation}
\label{sec:Data Duplication and Pre-Aggregation}
Data duplication might boost performance. As we have seen, \cstore~and \vertica~allow for storing columns in multiple sort orders at the same time in different projections \cite{Lamb2012-kg, Stonebraker2005-qz}. Different sort orders for columns can benefit different queries. The extra storage needed to store multiple sort orders are justified by the compression enabled by column storage. In \cstore~and \vertica, the projections and sort orders are defined by a database administrator. 

\blink~allows for storing columns in multiple banks, such that more predicates can be evaluated within the same bank, which in turn improves performance \cite{Johnson2008-cp}. This method is a unusual form of data duplication because it does not take up more space; only columns that fit within the free space in a word are duplicated. In Figure \ref{fig:banked-layout}, this means the $A$ column can be placed in both bank $\beta 1$ and $\beta 2$, since $A$ fits within $\beta 2$ as well.

In a distributed environment, data can be duplicated across nodes. \exasol~replicates tables across nodes in the system if they are small enough, such that queries can be processed locally, or, in other words, more efficiently. In a \bi~scenario, this typically means the dimension tables are replicated across different nodes. Table duplication across nodes turns costly global operations into cheap local ones \cite{Exasol2014-xh}.

Historically, data has been pre-aggregated to achieve good performance. However, pre-aggregation is inflexible and is considered as one of the main issues with old OLAP systems \cite{Boncz2002-yj}. Due to the lack of flexibility, most modern systems studied in this research do pre-aggregate results. For instance, both \sapnw~\cite{Lemke2010-is} calculate all results as needed. \qlikview~also calculates all results on-the-fly, but as we saw in Section \ref{sub:Data Import}, some aggregation and pre-joining can happen in the data import step.

\section{Caching and Dynamic Index Generation}
\label{sec:Caching and Dynamic Index Generation}
To improve performance and keep a database system scalable, caching can be used \cite{Plattner2014-fr}. \exasol~is a system that uses caching extensively \cite{Exasol2014-xh}. This DBMS stores the results of previous queries along with metadata that allows the system to decide if records are still valid. \term{VertiPaq}, an in-memory engine from \pn{Microsoft}, has better read performance for analytical queries compared to \mssql~due to caching \cite{Ferrari2012-hm}.

In \bd~products, which are mostly read-only, caching can be used more aggressively than for a general purpose DBMS. In \qlikview~and \tableau, the server has a central cache function which means that many calculations are only performed once \cite{Kamkolkar2015-iq, Qlik2011-ef}. When deciding which results to cache, the system takes into consideration how long it takes to generate the results \cite{noauthor_undated-js}. Caching gives better user experience and lower the CPU footprint. In these applications, cache is shared among different users on the same server.

\exasol~uses caching and dynamic index generation to improve filter and join operations \cite{Exasol2014-xh}. Internally, the system may produce and maintain indexes as needed. For instance, the result of a specific filter operation might be stored as an index in the system, and reused if the system encounters the same filter operation once more.

Caching of results and dynamic indexes raise a security issue in \bd~applications. For instance, both \qlikview~and \tableau~share caches among users. In Section \ref{sub:Security Settings}, we saw that these products have the ability to dynamically filter data based on the current user. This implies that cached results for one user might be invalid for others. Our research has been unsuccessful in identifying specific techniques to overcome this challenge, but we believe a solution could be to have separate or semi-separate caches per user.

\section{Chapter Conclusion}
\label{sec:Chapter Conclusion}
We conclude this chapter by pointing at \biti~as the most promising index structure. It is well suited for analytical workloads, handles \texttt{WHERE} clauses well, and can be used as a join index when applied to foreign columns. We also suggest looking into how the bitmap indexes can be compressed, for instance using \algmet{WAH} compression.

We find \term{Database Statistics} to be important for query performance. By checking minimum and maximum values for column partitions, local clustering can be exploited, and data can easily be pruned. If columns partitions have separate dictionaries, we suggest using this to see if a value exists within a block.

We see that our reference products, \qlikview~and \tableau, cache data and query results. The same is the case for \exasol, which also creates, maintains, and deletes indexes as needed. We, therefore, conclude that caching is a promising technique for a \bd~application. Caching should not be limited to query results, intermediate structures used in join and filter operations should also be stored and used later.

We are reluctant to recommend inverted indexes~in a \bd~product. They consume much memory, and we are unsure of how important single value lookups will be in a \bd~application.

