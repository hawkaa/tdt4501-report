\chapter{Background Information}
\label{chap:background}
\begin{secex}
This chapter will introduce relevant background information.
\begin{enumerate}
  \item Analytical vs Tranasctional workloads. How they normally was a separate system, but wants to unite. Use the Pavlic thesis on this. Star and snowflake schema?
  \item Background on column stores.
  \item Background on in-memory storages.
  \item Background on compression.
  \item Background on business intelligence and how it evolved into business discovery. Should explain the nature of the queries, and that they cannot be anticipated. Perhaps something about non-SQL type of queries.
  \item Predicate evaluation
  \item Background on testing (TPC-H, Snowflake, TPC-CH ++)
  \item Background on which vendors are out there. Explain the TPC-H benchmark, and which vendors are on top.
  \item Bacground on cardinality of columns
  \item NUMA
  \item Selectivity
\end{enumerate}
\end{secex}
\clearpage

\input{background/bi}
\input{background/imds}
\input{background/column-store}

\section{Data skew}
\label{sec:Data skew}
It is quite common that data is skewed. Typically, for a retailer, 99\% of the sales is done on weekdays, 40\% around christmas \cite{Raman2008-gi}. Although said to improve cache locality \cite{Larson2013-mc}, it is important that structures, compression schemes, and algorithms takes data skew into account. An example of this is \term{PForDelta}, which is a compression that builds on bit packing \cite{Bjorklund2011-wh}. In this scheme, outliers are not bit packed.

Data skew can be modelled with a \term{Zipfian} distribution \cite{Holloway2008-rr}.


\section{Reference products}
\label{sec:Reference products}
By reference products, we mean systems which the Business Intellingence capabilities in \genusSoftware. Products studied in this thesis is mainly \qlikview~and \tableau.

In these applications, the notion of \term{Business Discovery} is introduced \cite{Kamkolkar2015-iq, Qlik2014-vd}. These products allows users to follow ther "information scent" or "train of though". In general, these systems help IT organizations get out of reporting backlogs.

\subsection{How these applications work}
\label{sub:How these applications work}
The main requirements for a business discovery product user interface are \cite{Qlik2014-vd}:
\begin{itemize}
  \item Clicking field values in list boxes.
  \item Lassoing data in charts and graphs and maps.
  \item Manipulating sliders.
  \item Choosing dates in calendars.
  \item Cycling through various charts.
  \item ++
\end{itemize}
In the graphical user interface, \qlikview~follows a simple coloring strategy. Green means selected, white means matched, and gray means un-matched. The latter is important, since Business Discovery is not always about what is there, but also what is not present.

\missingfigure{Insert figure on non-hierarchical data from Qlik2014-vd}
Another important point in these applications, is that they have a state \cite{Qlik2014-vd}. Calculations are normally not preaggregated, they are calculated as needed. 

\missingfigure{Figure from Qlik2010-ya on Business Discovery associativity}

\qlikview~lets the user design data marts and user interface \cite{Qlik2011-ef}. The application is published through a server.

\tableau~works similarly, however, in addition to the built in in-memory engine, the application allows for connecting directly to database servers \cite{Kamkolkar2015-iq}. This way, the users can utilize investments in high-performance databases. \tableau~emphasizes the need for running the database on a server, since mobile devices must be supported. 

In terms of metadata management, both IT and business employees are empowered to modify it.

\qlikview~assumes a star or snowflake schema in the data extract design, that is no more than one possible join path between any pair of tables \cite{noauthor_undated-js}.

\subsection{Performance}
\label{sub:Performance}
These systems have the ultimate goal to perform well, however several factors contribute to the system overall performance. When considering performance, it is done from an end-user perspective \cite{Qlik2011-yc}.

\qlikview~outlines four aspects of this: Size of data, number of users, number of applications, and application design. The latter aspect means you should avoid too many listboxes, too many tables, too many formulas. In addition to this, columns should be split for better compression, and only pick the fields that are needed.

\subsection{Security settings}
\label{sub:Security settings}

The main \qlikview~security setting is the document-level authorization \cite{Qlik2011}. Using this technique, certain documents, or data extracts, are restricted to certain users. This way, several data marts with different data extracts can be served to the various user groups. In addition to this, a dynamic filter can be applied to the data, such that new data marts do not need to be defined for every use case. Fields an columns can be removed using a special \texttt{OMIT} keyword.

As for \tableau, data-level and user-level security is supported \cite{Kamkolkar2015-iq}. Data can be filtered per user as long as the filter matches a where-clause. Like \qlikview, \tableau~can limit the access to different reports and views.

\saph~has special support for analytical privileges that filters the data or applies drill-down limitations \cite{Primsch2011-ij}.

\section{Testing analytical workloads}
\label{sec:Testing analytical workloads}
To test analytical workloads, it is common to use the TPC-h benchmark \cite{Boncz2002-yj}. This is used for ad-hoc querying. To test for large data-sets, a scaling factor (SF) can be used. The TPC-H query focus on expression calculation, and consists of queries that are both memory and CPU bound \cite{Boncz2005-wj}.

Of other benchmarks, we see Star Schema Benchmark \cite{Boncz2002-yj}

As mentioned in Section X, a \term{Zipfian} distribution can be used to model data skew.

As a practical test for how much memory and CPU you need, the \qlikview~developers suggest to deploy a smaller scale deployment, and measure resource usage and do a linear extrapolation \cite{Qlik2011-yc}.

Other ways to test the implementation, includes using \pn{callgrind} to observer branches and cache effects \cite{Neumann2011-uq}, \pn{Intel Performance Counter Monitor} to measure cycles and nanoseconds \cite{Willhalm2013-ri}, and \pn{JMeter} to test user interaction.
