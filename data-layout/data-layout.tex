\chapter{Data Layout}
\label{chap:Data Layout}
One of the most prevalent ways of achieving good performance for OLAP workloads, is to consider how the data is laid out in all levels of the memory hierarchy. Most of the discussion relates to column stores against row stores, but we see alternate ways of storing the data. In addition to the overall storage format, one should also consider if and how to partition the data, and how to sort it.
\newpage

\section{Column storage}
\label{sec:Column storage}
As mentioned before, the most common way for transactional workloads has been to store data in rows. However many database systems use columnar storage instead of row storage to enhance aggregation and predicate evaluation performance. This includes the MonetDB \cite{Boncz2002-yj, Boncz2005-wj}, C-Store \cite{Stonebraker2005-qz}, SAP HANA \cite{Farber2012-vh}, and Microsoft SQL Server \cite{Larson2013-mc, noauthor_undated-vq}, as well as the Business Discovery product Tableau \cite{Kamkolkar2015-iq}. 

The main argument is that you don't need to access more columns than strictly necessary. \todo{Insert stuff about that here}. Another argument for column storage is that columns have low degree of freedom, they only need to know about the local memory offset and not the global table layout \cite{Boncz2005-wj}.

MonetDB, one of the earlier database systems using a columnar storage used it because \todo{fill in about MonetDB} \cite{Boncz2002-yj}. The arguments from Stonebraker \ea~\cite{Stonebraker2005-qz} are similar, but since C-store stores their data in multiple sort orders, it can be compressed even more.. SQL Server argues for column store \cite{noauthor_undated-vq}: High compression rates, and better performance due to memory utilization

However, the most important piece of literature Abadi \ea~investigated wheter there was a fundamental difference between row and column stores, and tried to mimic columnar behavior in a commercial row store \cite{Abadi2008-dd} . The conclusion was that there is something fundamental about column stores that make them perform so well, and this includes compression (Chapter x), vectorized execution (Section x) and late materialization (Section y). \todo{Make this article a big deal}

Column stores have been said to be more compressible, as we see in Chapter 4 is important to achieve good performance.

Although much points at a column or hybrid layout is the most beneficial for analytical workloads, Holloway \ea \cite{Holloway2008-rr} investigated in which occurences a row store actually could be beneficial. One of the major findings from this paper is that row stores are just as compressible as column stores if done right.

\ffigure{img/chain-reaction.png}{OLTP workloads will affect more than a couple of rows. Index structures must be maintained, and preaggregations and matrealized views must be updated. In the figure, an update that triggers a chain reaction is depicted. Courtesy of \cite{Plattner2014-fr}.}{fig:chain-reaction}
There are papers claiming OLTP also benefits from a columnar storage. The work of Farber \ea~\cite{Farber2012-vh} argues that columnar storage is suited for OLTP as well, due to the compression. In addition, there are more read operations in an OLTP than one originally thinks. Lastly, indexes can be dropped. The work of Plattner \ea~\cite{Plattner2014-fr} claim that most OLTP queries ask for aggregates, not only one row. It triggers a series of aggregate, as seen in Figure \ref{fig:chain-reaction}. Lastly, data footprint and application development gets easier.

\subsection{Column projections}
\label{sub:Column projections}
C-store allows to have several projections per column, with different sort order. They claim the redundant storage is justified by the additional compression. Configuring these projections requires a DBA. \pn{Vertica}, a commercialized version of \pn{C-Store} supports several narrow projections in addition to one super projection.

\subsection{Horizontal partitioning of columns}
\label{sub:Horizontal partitioning of columns}
Several products splits the columns horizontally, and if the columns are split, each block normally has its own dictionary (see the Compression chapter). There are several orthogonal arguments for this:
\begin{itemize}
  \item Storing metadata values, like minimum and maximum per block allows for cluster exploitation and easy pruning of data.
  \item Smart partitioning of data based on the value frequencies handles data skew, and allows for improved compression rates.
  \item Horizontal partitions can be spread out across different nodes in a distributed environment.
\end{itemize}

\ffigure{img/mssql-row-group.png}{Illustrating how a column store index in \mssql is created and stored. The set of rows is divided into row groups that are converted to column segments and dictionaries. Courtesy of \cite{Larson2013-mc}.}{fig:mssql-row-group}
Microsoft SQL server operate on \textit{row groups} which are groups of rows compressed into a columnar format. The number of rows in a row group must me small enough to benefit from in-memory operations and large enough to achive high compression rates. Data within these are not sorted, and they are encoded and compressed independently. Each row group has their own dictionary, as seen in Figure~\ref{fig:mssql-row-group}.

For Oracle Database in-memory option, the column store is made up of multiple extents, called In-Memory Compression Units (IMCUs). Data is loaded into these units without sorting, they are put in the same way as it appears in the row format. Each chunk constists of approximately half a million rows, and each block is assigned max and minimum values per column such that data can easily be pruned.

The \pn{Blink} database and IBM DB2 with BLU acceleration  \cite{Barber2012-xt, Raman2013-em, Raman2008-gi} uses frequency partitioning and horizontally partitions the rows based on the frequency which values incur in a column at load time, and has a positive effect on data skew. Rows are partitioned into pages, and each page is indexed using a B+ tree.

\pn{EXASOL} distributes data horizontally for parallelization and balance.

\subsection{Sorting of values}
\label{sub:Sorting of values}
There is little indication in the literature that it is common to sort the values in the columns. This has been explicitly mentioned being the case for Microsof SQL Server \cite{Larson2013-mc} and Blink \cite{Raman2013-em}, and it is the case for \pn{Oracle Database}.

There are however benefits in sorting the values in the column store. First of all, single value lookups are easily performed by a binary search (however, this limitation can be overcome by keeping inverted indexes \cite{Lemke2010-is}, \cite{Schwalb2014-hn}) Second, and perhaps most important, is that sorted columns can be compressed aggressively by applying run-length encoding (read more about this in the Compression chapter). This is the reason why C-store \cite{Stonebraker2005-qz} lets the DBA define projections of various sort orders.

\subsection{Row identifiers}
\label{sub:Row identifiers}
In order to stitch together the rows after a query has been executed, each row needs a unique identifier. Many of the systems store these implicitly \cite{Boncz2002-yj, Raman2013-em, Stonebraker2005-qz, Lamb2012-kg} as a virtual object ID (void). Microsoft SQL Server identifies a row by a combination of row group ID and tuple ID \cite{Larson2013-mc}.


\section{Alternative storage layouts}
\label{sec:Alternative storage layouts}
Although column storage is normally seen as superior to row storage on analytical workloads, some related work have questioned this.

\ffigure{img/oracle-dual.png}{The \oracle~dual format. Courtesy of \cite{Oracle2015-fs}.}{fig:oracle-dual}
The Oracle Database in-memory \cite{Lahiri2015-mz} offers a dual format, where data is stored as both columns and rows. As we see in Figure~\ref{fig:oracle-dual}, the rows are used for transactional workloads, while the columns are used for analycits. Since analytical indexes can be dropped when using a column layout, and that the columns are heavily compressed, this does not take more space than usual. IBM 2 with BLU acceleration \cite{Raman2013-em} does not save the data in both ways, but collumns and rows might co-exist in the same table.

\ffigure{img/banked-layout.png}{Banked layout. Courtesy of \cite{Johnson2008-cp}.}{fig:banked-layout}
The work of Barber \ea \cite{Barber2012-xt} claims that both row and column store is suboptimal, and claim that columns are ineffective because they must be padded to word boundaries for efficient access. Their database system, \pn{Blink} therefore implement a hybrid structure, where a subset of the rows are densely packed in word banks, typcially 128-256 bits each. \pn{Blink} puts data into banks, and each column has fixed bits within that bank. A bank is normally a machine word length \cite{Johnson2008-cp} A later paper on \pn{Blink} \cite{Raman2013-em} however contradicts this format, and says everything is stored column-wise.

\ffigure{img/pax.png}{PAX layout for example tuples. Courtesy of \cite{Bjorklund2011-wh}.}{fig:pax}
Another popular format is the PAX (Partition Attributes Across) data layout \cite{Holloway2008-rr, Bjorklund2011-wh} which can be seen in Figure \ref{fig:pax}. This format allows for column-wise storage of tuples per page, and increases cache behavior. However, this does not reduce IO. Tuples are stored together in pages, but within each page, the data is stored in columns.

