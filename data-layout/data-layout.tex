\chapter{Data Layout}
\label{chap:Data Layout}
One of the most prevalent ways of achieving good performance for OLAP workloads, is to consider how the data is laid out in all levels of the memory hierarchy. Most of the discussion relates to column stores against row stores, but we see alternate ways of storing the data. In addition to the overall storage format, one should also consider if and how to partition the data, and how to sort it.
\newpage

\ffigure{img/row-store.png}{Row-oriented layout for example tuples. Courtesy of \cite{Bjorklund2011-wh}.}{fig:row-store}
\ffigure{img/column-store.png}{Column-oriented layout for example tuples. Courtesy of \cite{Bjorklund2011-wh}.}{fig:column-store}
\section{Column storage}
\label{sec:Column storage}
Briefly mentioned in Section \ref{sub:History}, the most common storage format for transactional workloads (OLTP systems) has been to store the data in rows. Row storage enables easy fetching of related data, as well as being suited for updates, inserts, and deletes. However, for OLAP workloads, columnar storage has turned out advantageous since data is more easily aggregated and only the attributes required for the query are fetched. Systems supporting column store include, but are not limited to, MonetDB \cite{Boncz2002-yj, Boncz2005-wj}, C-Store \cite{Stonebraker2005-qz}, SAP HANA \cite{Farber2012-vh}, and Microsoft SQL Server \cite{Larson2013-mc, noauthor_undated-vq}, as well as the Business Discovery product Tableau \cite{Kamkolkar2015-iq}. 

In a column store, each column in a table is stored separately in a continous segment (unless data is horizontally partitioned, see Section \ref{sub:Horizontal partitioning of columns}), as opposed to row stores where attributes from a single row is stored together \cite{Bjorklund2011-wh}. Row and column layout are depicted in Figure \ref{fig:row-store} and Figure \ref{fig:column-store} respectively. When executing a query on a column store, only the columns needed for the query is fetched and processed. However, the results of most queries in a DBMS is returned as rows, so columns must be stiched together before the result is returned. Since the different columns are stored on different locations, inserting new values is slightly more involved than in a row store. 

We find that the main argument is that you don't need to access more columns than strictly necessary. In addition, the columns are inherently more compressible. Hence, these arguments relates to memory footprint, and in disk-based databases, RAM is better utilized. This is explicitly mentioned by the authors of \mssql; High compression rates, and better performance due to memory utilization. We also know from the introduction that reduction in memory footprint is directly correlated to CPU cache pressure. \todo{Find more arguments, more citations, c-store, monetdb \cite{Boncz2002-yj}}

\textit{Could we insert another paragraph about the advantages of columnr storage here?}


Relevant for both disk-based and memory-based database systems is that columns have low degree of freedom, they only need to know about the local memory offset and not the global table layout \cite{Boncz2005-wj}. More specifically, this means that in terms of implementation, layers of indirection is avoided, because you know where to find each column value based on the base location when iterating a column. \todo{Elaborate}

One of the major disadvantages with column store is that it is not as easily updateable \cite{Bjorklund2011-wh}, especially if the columns are compressed or sorted. This challenge is normally overcome using a separate structure for writes and updates called a delta store. The main part of the database is stored column wise in a static structure optimized for reads, while the rest is accumulated in a smaller and more dynamic structure. We investigate delta stores further in Section \ref{sub:Delta Store}.

\ffigure{img/chain-reaction.png}{OLTP workloads will affect more than a couple of rows. Index structures must be maintained, and preaggregations and matrealized views must be updated. In the figure, an update that triggers a chain reaction is depicted. Courtesy of \cite{Plattner2014-fr}.}{fig:chain-reaction}
There are papers claiming OLTP also benefits from a columnar storage. The work of Farber \ea~\cite{Farber2012-vh} argues that columnar storage is suited for OLTP as well, due to the compression. In addition, there are more read operations in an OLTP than one originally thinks. Lastly, indexes can be dropped. The work of Plattner \ea~\cite{Plattner2014-fr} claim that most OLTP queries ask for aggregates, not only one row. It triggers a series of aggregate, as seen in Figure \ref{fig:chain-reaction}. Lastly, data footprint and application development gets easier.

\subsection{Sorting}
\label{sub:Sorting}
We see that few systems sort the data values before storing them inside columns. An exception to this is \cstore, and later \vertica \cite{Stonebraker2005-qz, Lamb2012-kg}. Here, different projections (subsets of the colums) may be defined, and each projection has its own sort order. Sorting the values in the columns enables binary search for single values in columns, which normally would be done by inverted indexes. In addition, sorted values improves compression and query performance through the use of Run-Length Encoding. We look into Run-Length encoding in Section \ref{sec:Run-Length Encoding}.

Although most systems do not sort the columns directly and insert values at the bottom of the columns when they arrive, many systems have a sorted dictionary when dictionary encoding is used. We look into dictionary encoding in Section \ref{sec:Dictionary Encoding}.

There is little indication in the literature that it is common to sort the values in the columns. This has been explicitly mentioned being the case for Microsof SQL Server \cite{Larson2013-mc} and Blink \cite{Raman2013-em}, and it is the case for \pn{Oracle Database}.

There are however benefits in sorting the values in the column store. First of all, single value lookups are easily performed by a binary search (however, this limitation can be overcome by keeping inverted indexes \cite{Lemke2010-is}, \cite{Schwalb2014-hn}) Second, and perhaps most important, is that sorted columns can be compressed aggressively by applying run-length encoding (read more about this in the Compression chapter). This is the reason why C-store \cite{Stonebraker2005-qz} lets the DBA define projections of various sort orders.

\subsection{Row Stores vs. Column Stores}
\label{sub:Row Stores vs. Column Stores}
However, the most important piece of literature Abadi \ea~investigated wheter there was a fundamental difference between row and column stores, and tried to mimic columnar behavior in a commercial row store \cite{Abadi2008-dd} . The conclusion was that there is something fundamental about column stores that make them perform so well, and this includes compression (Chapter x), vectorized execution (Section x) and late materialization (Section y). \todo{Make this article a big deal}

Although much points at a column or hybrid layout is the most beneficial for analytical workloads, Holloway \ea \cite{Holloway2008-rr} investigated in which occurences a row store actually could be beneficial. One of the major findings from this paper is that row stores are just as compressible as column stores if done right. This \textcolor{red}{contradicts} other research, most research say column stores are more compressible than row storage

\subsection{Row identifiers}
\label{sub:Row identifiers}
In order to stitch together the rows after a query has been executed, each row needs a unique identifier. Many of the systems store these implicitly \cite{Boncz2002-yj, Raman2013-em, Stonebraker2005-qz, Lamb2012-kg} as a virtual object ID (void). Microsoft SQL Server identifies a row by a combination of row group ID and tuple ID \cite{Larson2013-mc}.

% MonetDB, one of the earlier database systems using a columnar storage used it because \todo{fill in about MonetDB} \cite{Boncz2002-yj}. The arguments from Stonebraker \ea~\cite{Stonebraker2005-qz} are similar, but since C-store stores their data in multiple sort orders, it can be compressed even more.. SQL Server argues for column store \cite{noauthor_undated-vq}:


%\subsection{Column projections} MOVE TO INDEX, CACHING ETC
%\label{sub:Column projections} 
%C-store allows to have several projections per column, with different sort order. They claim the redundant storage is justified by the additional compression. Configuring these projections requires a DBA. \pn{Vertica}, a commercialized version of \pn{C-Store} supports several narrow projections in addition to one super projection.

\section{Horizontal Partitioning}
\label{sec:Horizontal Partitioning}
Several systems split data horizontally. In a column store, each block normally has its own dictionary (see the Compression chapter). Partitioning data horizontally can be beneficial due to the following reasons \todo{Add citations to these points}:
\begin{itemize}
  \item Storing metadata values, like minimum and maximum per block allows for cluster exploitation and easy pruning of data.
  \item Smart partitioning of data based on the value frequencies handles data skew, and allows for improved compression rates.
  \item Horizontal partitions can be spread out across different nodes in a distributed environment.
  \item Horizontal partitions can be created one at a time, such that new insertions will not affect already existing partitions.
\end{itemize}

\ffigure{img/mssql-row-group.png}{Illustrating how a column store index in \mssql~is created and stored. The set of rows is divided into row groups that are converted to column segments and dictionaries. Courtesy of \cite{Larson2013-mc}.}{fig:mssql-row-group}
Microsoft SQL server operate on \textit{row groups} which are groups of rows compressed into a columnar format. The number of rows in a row group must me small enough to benefit from in-memory operations and large enough to achive high compression rates. Data within these are not sorted, and they are encoded and compressed independently. Each row group has their own dictionary, as seen in Figure~\ref{fig:mssql-row-group}.

For Oracle Database in-memory option, the column store is made up of multiple extents, called In-Memory Compression Units (IMCUs). Data is loaded into these units without sorting, they are put in the same way as it appears in the row format. Each chunk constists of approximately half a million rows, and each block is assigned max and minimum values per column such that data can easily be pruned.

\afigure{img/frequency-partitioning.png}{Frequency partitioning in \blink. Courtesy of \cite{Raman2008-gi}.}{fig:frequency-partitioning}{0.6}
The \pn{Blink} database and IBM DB2 with BLU acceleration  \cite{Barber2012-xt, Raman2013-em, Raman2008-gi} uses frequency partitioning and horizontally partitions the rows based on the frequency which values incur in a column at load time, and has a positive effect on data skew. Rows are partitioned into pages, and each page is indexed using a B+ tree. See Figure \ref{fig:frequency-partitioning}.

\pn{EXASOL} distributes data horizontally for parallelization and balance.


\section{Alternative storage layouts}
\label{sec:Alternative storage layouts}
Although column storage is normally seen as superior to row storage on analytical workloads, some related work have questioned this.

\ffigure{img/oracle-dual.png}{The \oracle~dual format. Courtesy of \cite{Oracle2015-fs}.}{fig:oracle-dual}
The Oracle Database in-memory \cite{Lahiri2015-mz} offers a dual format, where data is stored as both columns and rows. As we see in Figure~\ref{fig:oracle-dual}, the rows are used for transactional workloads, while the columns are used for analycits. Since analytical indexes can be dropped when using a column layout, and that the columns are heavily compressed, this does not take more space than usual. IBM 2 with BLU acceleration \cite{Raman2013-em} does not save the data in both ways, but collumns and rows might co-exist in the same table.

\ffigure{img/banked-layout.png}{Banked layout. Courtesy of \cite{Johnson2008-cp}.}{fig:banked-layout}
The work of Barber \ea \cite{Barber2012-xt} claims that both row and column store is suboptimal, and claim that columns are ineffective because they must be padded to word boundaries for efficient access. Their database system, \pn{Blink} therefore implement a hybrid structure, where a subset of the rows are densely packed in word banks, typcially 128-256 bits each. \pn{Blink} puts data into banks, and each column has fixed bits within that bank. A bank is normally a machine word length \cite{Johnson2008-cp} A later paper on \pn{Blink} \cite{Raman2013-em} however contradicts this format, and says everything is stored column-wise.

\ffigure{img/pax.png}{PAX layout for example tuples. Courtesy of \cite{Bjorklund2011-wh}.}{fig:pax}
Another popular format is the PAX (Partition Attributes Across) data layout \cite{Holloway2008-rr, Bjorklund2011-wh} which can be seen in Figure \ref{fig:pax}. This format allows for column-wise storage of tuples per page, and increases cache behavior. However, this does not reduce IO. Tuples are stored together in pages, but within each page, the data is stored in columns.

\section{Chapter Conclusion}
\label{sec:Chapter Conclusion}
We see that most litterature agrees that column storage is advantegeous for read-optimized databases due to lower memory footprint. We believe columnar storage is well suited for \bd~products. We also propose horizontal partitioning.

It does not agree on some aspects. First, column stores have been said to be more compressible than row stores. This is challenged by X. In addition, row stores is said to be more suited for OLTP workloads. However, X claims that column stores is suited for OLTP workloads as well.

