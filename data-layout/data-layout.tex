\chapter{Data Layout}
\label{chap:Data Layout}
One of the most prevalent ways of achieving good performance for OLAP workloads, is to consider how the data is laid out in all levels of the memory hierarchy. Most of the discussion relates to column stores against row stores, but we see alternate ways of storing the data. In addition to the overall storage format, one should also consider if and how to partition the data, and how to sort it.
\newpage

\ffigure{img/row-store.png}{Row-oriented layout for example tuples. Courtesy of \cite{Bjorklund2011-wh}.}{fig:row-store}
\ffigure{img/column-store.png}{Column-oriented layout for example tuples. Courtesy of \cite{Bjorklund2011-wh}.}{fig:column-store}
\section{Column storage}
\label{sec:Column storage}
Briefly mentioned in Section \ref{sub:History}, the most common storage format for transactional workloads (OLTP systems) has been to store the data in rows. Row storage enables easy fetching of related data, as well as being suited for updates, inserts, and deletes. However, for OLAP workloads, columnar storage has turned out advantageous since data is more easily aggregated and only the attributes required for the query are fetched. Systems supporting column store include, but are not limited to, MonetDB \cite{Boncz2002-yj, Boncz2005-wj}, C-Store \cite{Stonebraker2005-qz}, SAP HANA \cite{Farber2012-vh}, and Microsoft SQL Server \cite{Larson2013-mc, noauthor_undated-vq}, as well as the Business Discovery product Tableau \cite{Kamkolkar2015-iq}. 

In a column store, each column in a table is stored separately in a continous segment (unless data is horizontally partitioned, see Section \ref{sub:Horizontal partitioning of columns}), as opposed to row stores where attributes from a single row is stored together \cite{Bjorklund2011-wh}. Row and column layout are depicted in Figure \ref{fig:row-store} and Figure \ref{fig:column-store} respectively \todo{SEB 30/11: Explain figure, I and P}. When executing a query on a column store, only the columns needed for the query is fetched and processed. However, the results of most queries in a DBMS is returned as rows, so columns must be stiched together before the result is returned, which implies an overhead. In addition, since the different columns are stored on different locations, inserting new values is slightly more involved than in a row store. 

We find that the main argument is that you do not need to access more columns than strictly necessary. In addition, the columns are inherently more compressible. Hence, these arguments relates to memory footprint, and in disk-based databases, RAM is better utilized. This is explicitly mentioned by the authors of \mssql; High compression rates, and better performance due to memory utilization \cite{noauthor_undated-vq}. We also know from the introduction that reduction in memory footprint is directly correlated to CPU cache pressure. \todo{Find more arguments, more citations, c-store, monetdb \cite{Boncz2002-yj}}

\textit{Could we insert another paragraph about the advantages of columnr storage here?}

Relevant for both disk-based and memory-based database systems is that columns have low degree of freedom, they only need to know about the local memory offset and not the global table layout \cite{Boncz2005-wj}. More specifically, this means that in terms of implementation, layers of indirection is avoided, because you know where to find each column value based on the base location when iterating a column. \todo{Elaborate, SEB 30/11: Thought it was "high" istead of "low"}

One of the major disadvantages with column store is that it is not as easily updateable \cite{Bjorklund2011-wh}, especially if the columns are compressed or sorted. This challenge is normally overcome using a separate structure for writes and updates called a delta store. The main part of the database is stored column wise in a static structure optimized for reads, while the rest is accumulated in a smaller and more dynamic structure. We investigate delta stores further in Section \ref{sub:Delta Store}.


\subsection{Sorting}
\label{sub:Sorting}
We see that few systems sort the data values before storing them inside columns. An exception to this is \cstore, and later \vertica \cite{Stonebraker2005-qz, Lamb2012-kg}. Here, different projections (subsets of the colums) may be defined, and each projection has its own sort order. We look further into column projectins in Section \ref{sub:Column projections}. Sorting the values in the columns enables binary search for single values in columns, which normally would be done by inverted indexes. In addition, sorted values improves compression and query performance through the use of Run-Length Encoding. We look into Run-Length encoding in Section \ref{sec:Run-Length Encoding}.

There are  benefits in sorting the values in the column store. First of all, single value lookups are easily performed by a binary search (however, this limitation can be overcome by keeping inverted indexes \cite{Lemke2010-is, Schwalb2014-hn}) Second, and perhaps most important, is that sorted columns can be compressed aggressively by applying run-length encoding (read more about this in the Compression chapter). This is the reason why C-store \cite{Stonebraker2005-qz} lets the DBA define projections of various sort orders.

Except from \cstore~and \vertica, there is little indication in the literature that it is common to sort the values in the columns. Of the research we have covered in this thesis, we find that \mssql~\cite{Larson2013-mc}, \blink~\cite{Raman2013-em} and \oracle~\cite{Lahiri2015-mz} accept values in the order they appear. However, there has been cases where research have sorted columns prior to testing, such that Run-Length encoding is maximized \cite{Holloway2008-rr}. \blink~has also reported a performance increase if the columns are sorted \cite{Johnson2008-cp}.

Although most systems do not sort the columns, that is values are insert in the same order as they arrive, many systems have a sorted dictionary when dictionary encoding is used. Systems here include \blink~\cite{Johnson2008-cp} and \saph~\cite{Farber2012-vh}. A sorted dictionary has many advantages, like easy lookup for single values, transformation of range predicates to \texttt{IN}-list predicates, and partition pruning. However, keeping the dictionary structure sorted in a dynamic environment implies a large overhead, so sorted dictionaries are better suited for read-only columns. We look into dictionary encoding in Section \ref{sec:Dictionary Encoding}.

\subsection{Row Stores vs. Column Stores}
\label{sub:Row Stores vs. Column Stores}
However, the most important piece of literature Abadi \ea~investigated wheter there was a fundamental difference between row and column stores, and tried to mimic columnar behavior in a commercial row store \cite{Abadi2008-dd} . The conclusion was that there is something fundamental about column stores that make them perform so well, and this includes compression (Chapter x), vectorized execution (Section x) and late materialization (Section y). \todo{Make this article a big deal}

Although much points at a column or hybrid layout is the most beneficial for analytical workloads, Holloway \ea \cite{Holloway2008-rr} investigated in which occurences a row store actually could be beneficial. In low selectivities, bla bla, and if the columns are bla bla... One of the major findings from this paper is that row stores are just as compressible as column stores if done right. This \textcolor{red}{contradicts} other research, most research say column stores are more compressible than row storage. \todo{Fill in the paragraph about this. SEB 30/11: Dues not buy that rows are as compressible.}

\ffigure{img/chain-reaction.png}{OLTP workloads will affect more than a couple of rows. Index structures must be maintained, and preaggregations and matrealized views must be updated. In the figure, an update that triggers a chain reaction is depicted. Courtesy of \cite{Plattner2014-fr}.}{fig:chain-reaction}
There are papers claiming OLTP also benefits from a columnar storage. The work of Farber \ea~\cite{Farber2012-vh} argues that columnar storage is suited for OLTP as well, due to the compression. In addition, there are more read operations in an OLTP than one originally thinks. Lastly, indexes can be dropped. The work of Plattner \ea~\cite{Plattner2014-fr} claim that most OLTP queries ask for aggregates, not only one row. It triggers a series of aggregate, as seen in Figure \ref{fig:chain-reaction}. Lastly, data footprint and application development gets easier.

\subsection{Row Identifiers}
\label{sub:Row Identifiers}
In order to stitch together the rows after a query has been executed, each row needs a unique identifier. Many of the systems store these implicitly \cite{Boncz2002-yj, Raman2013-em, Stonebraker2005-qz, Lamb2012-kg} as a virtual object ID (void). If horizontal partitioning is used, this must also be addressed in the identification of rows. Microsoft SQL Server identifies a row by a combination of row group ID and tuple ID \cite{Larson2013-mc}. \todo{SEB 30/11: Elaborate, explain how to stitch together rows}.

\section{Horizontal Partitioning}
\label{sec:Horizontal Partitioning}
Several systems split data horizontally. Partitioning data horizontally can be beneficial due to the following reasons \todo{Add citations to these points}:
\begin{itemize}
  \item Storing metadata values, like minimum and maximum per block allows for cluster exploitation and easy pruning of data. We look further into how database statistics can be utilized in Section \ref{sec:Table Statistics}.
  \item Horizontal partitions can be spread out across different nodes in a distributed environment. We look into scaling out horizontally in Section \ref{sec:Scaling Out}.
  \item Horizontal partitions can be created one at a time, such that new insertions will not affect already existing partitions.
  \item Smart partitioning of data based on the value frequencies handles data skew, and allows for improved compression rates.
  \item Enables parallelization and balance \cite{Exasol2014-xh}
\end{itemize}

\ffigure{img/mssql-row-group.png}{Illustrating how a column store index in \mssql~is created and stored. The set of rows is divided into row groups that are converted to column segments and dictionaries. Courtesy of \cite{Larson2013-mc}.}{fig:mssql-row-group}
Microsoft SQL server operate on \textit{row groups} which are groups of rows compressed into a columnar format. The number of rows in a row group must me small enough to benefit from in-memory operations and large enough to achive high compression rates. Data within these are not sorted, and they are encoded and compressed independently. Each row group has their own dictionary, as seen in Figure~\ref{fig:mssql-row-group}.

For Oracle Database in-memory option, the column store is made up of multiple extents, called In-Memory Compression Units (IMCUs). Data is loaded into these units without sorting, they are put in the same way as it appears in the row format. Each chunk constists of approximately half a million rows, and each block is assigned max and minimum values per column such that data can easily be pruned.

\afigure{img/frequency-partitioning.png}{Frequency partitioning in \blink. Courtesy of \cite{Raman2008-gi}.}{fig:frequency-partitioning}{0.6}
The \pn{Blink} database and IBM DB2 with BLU acceleration  \cite{Barber2012-xt, Raman2013-em, Raman2008-gi} uses frequency partitioning and horizontally partitions the rows based on the frequency which values incur in a column at load time, and has a positive effect on data skew. Rows are partitioned into pages, and each page is indexed using a B+ tree. See Figure \ref{fig:frequency-partitioning}.

We see that it is common that each partition has its own dictionary. This is not only the case for \mssql, \oracle, and \blink, but also ... By storing each dictionary in a partition, we see that \blink~benefits from increased compression rates. In addition, horizontal partitions can be skipped if the current predicate is not present in the dictionary, which we will read more about in Section \ref{sec:Dictionary Compression}.

\section{Alternative Storage Layouts}
\label{sec:Alternative Storage Layouts}
Although column storage is normally seen as superior to row storage on analytical workloads, some related work have questioned this.

\ffigure{img/oracle-dual.png}{The \oracle~dual format. Courtesy of \cite{Oracle2015-fs}.}{fig:oracle-dual}
\oracle offers a dual format, where data is stored as both columns and rows \cite{Lahiri2015-mz}. As we see in Figure~\ref{fig:oracle-dual}, the rows are used for transactional workloads, while the columns are used for analycits. Since analytical indexes can be dropped when using a column layout, and that the columns are heavily compressed, this does not take more space than usual. \ibm~does not save the data in both ways, but columns and rows might co-exist in the same table \cite{Raman2013-em}.

Another way of considering a column storage is through to consider the columns storages as index structures on the row store. \mssql~does not directly support column storage, that is the data is still persisted on disk in a row-wise fashion, but columns are built on top in-memory as an index structure \cite{noauthor_undated-vq}. Different from ordinary index structures, the columns are not used for value lookups, but for efficent OLAP processing, like batch and vectorized execution. \todo{Elaborate, add from other sources}

\ffigure{img/banked-layout.png}{Banked layout. Courtesy of \cite{Johnson2008-cp}.}{fig:banked-layout}
The work of Barber \ea \cite{Barber2012-xt} claims that both row and column store is suboptimal, and claim that columns are ineffective because they must be padded to word boundaries for efficient access. Their database system, \pn{Blink} therefore implement a hybrid structure, where a subset of the rows are densely packed in word banks, typcially 128-256 bits each. \pn{Blink} puts data into banks, and each column has fixed bits within that bank. A bank is normally a machine word length \cite{Johnson2008-cp} A later paper on \pn{Blink} \cite{Raman2013-em} however contradicts this format, and says everything is stored column-wise.

\ffigure{img/pax.png}{PAX layout for example tuples. Courtesy of \cite{Bjorklund2011-wh}.}{fig:pax}
Another popular format is the PAX (Partition Attributes Across) data layout \cite{Holloway2008-rr, Bjorklund2011-wh} which can be seen in Figure \ref{fig:pax}. This format allows for column-wise storage of tuples per page, and increases cache behavior. However, this does not reduce IO. Tuples are stored together in pages, but within each page, the data is stored in columns.

\section{Chapter Conclusion}
\label{sec:Chapter Conclusion}
We conclude that columnar storage looks promising for a \bd~application. Columnar storage reduces memory footprint by enabling compression, and relieves CPU cache pressure due since most data put into the cache is used. We find that most disadvantages with columnar storage is related to writes and updates, but since we focus on read-only performance, this does not apply. \todo{SEB 30/11: But the DB needs to be created and updated?}

We also suggest dividing columns horizontally. First, this enables data pruning if partition metadata, like min and max values are stored in each partition. Second, horizontal partitioning enables parallelization. Third, if updates is to be supported in the future, horizontal partitions can be added one by one.

Sorting of values and frequency partitioning can also be considered. Keeping columns sorted enables easy value lookup, and sorted columns compress better than unsorted columns with the use of \rle. Frequency partition allows better compression when there is data skew.
